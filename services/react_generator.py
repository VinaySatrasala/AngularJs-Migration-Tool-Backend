import json
import os
from pathlib import Path
import asyncio
from typing import Dict, List, Any, Optional, Union
import logging
import re
from tenacity import retry, stop_after_attempt, wait_exponential

# Set up logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class ReactComponentGenerator:
    """
    Generates React component files from AngularJS source files using AI assistance.
    
    This class takes the migration structure generated by ReactMigrationStructureGenerator
    and creates actual React component files, placing them in the correct directory structure.
    """
    
    def __init__(self, migration_file: str, analysis_file: str, output_dir: Union[str, Path], llm_config: Any):
        """
        Initialize the ReactComponentGenerator.
        
        Args:
            migration_file: Path to the JSON file containing the React migration structure
            analysis_file: Path to the JSON file containing the AngularJS project analysis
            output_dir: Directory where the React files will be created
            llm_config: Configuration for the language model
        """
        self.migration_file = migration_file
        self.analysis_file = analysis_file
        self.output_dir = Path(output_dir)
        self.llm_config = llm_config
        self.migration_data = {}
        self.analysis_data = {}
        self.source_files = {}
        
    async def load_data(self):
        """Load the migration structure and analysis data."""
        try:
            with open(self.migration_file, 'r', encoding='utf-8') as f:
                self.migration_data = json.load(f)
                
            with open(self.analysis_file, 'r', encoding='utf-8') as f:
                self.analysis_data = json.load(f)
                
            logger.info(f"Successfully loaded migration and analysis data")
            
            # Remove metadata entries if present
            if "__metadata__" in self.migration_data:
                del self.migration_data["__metadata__"]
                
            # Remove project_structure entry if present (appears to be a duplicate)
            if "project_structure" in self.migration_data:
                del self.migration_data["project_structure"]
                
            # Process the analysis data to extract source files
            self._extract_source_files()
            
        except Exception as e:
            logger.error(f"Error loading data: {str(e)}")
            raise
    
    def _extract_source_files(self):
        """Extract source files from the analysis data."""
        if not isinstance(self.analysis_data, dict):
            logger.error("Analysis data is not a dictionary")
            return
            
        for file_path, file_info in self.analysis_data.items():
            if not isinstance(file_info, dict):
                continue
                
            # Get the content from the analysis data
            content = file_info.get('content', '')
            if not content and 'file_path' in file_info:
                # Try reading from actual file if content not in analysis
                try:
                    with open(file_info['file_path'], 'r', encoding='utf-8') as f:
                        content = f.read()
                except Exception as e:
                    logger.warning(f"Could not read file {file_info['file_path']}: {str(e)}")
                    continue
            
            if content:
                # Store both relative and absolute paths for flexibility
                relative_path = file_info.get('relative_path', file_path)
                self.source_files[file_path] = content
                self.source_files[relative_path] = content
                
                # Also store without extension for more flexible matching
                base_path = os.path.splitext(file_path)[0]
                if base_path != file_path:
                    self.source_files[base_path] = content
                    
        logger.info(f"Extracted {len(self.source_files)} source files from analysis data")
    
    async def generate_all_components(self):
        """Generate all React components based on the migration structure."""
        if not self.migration_data:
            await self.load_data()
        
        total_files = len(self.migration_data)
        completed_files = 0
        failed_files = 0
        
        logger.info(f"Starting generation of {total_files} React components")
        
        # Create the base output directory
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        # Process each file in the migration structure
        tasks = []
        semaphore = asyncio.Semaphore(3)  # Limit concurrent API calls
        
        for file_path, file_data in self.migration_data.items():
            tasks.append(self._generate_with_semaphore(semaphore, file_path, file_data))
        
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # Count successful and failed generations
        for result in results:
            if isinstance(result, Exception):
                failed_files += 1
            else:
                completed_files += 1
        
        logger.info(f"Generated {completed_files}/{total_files} files successfully")
        if failed_files > 0:
            logger.warning(f"Failed to generate {failed_files} files")
        
        return completed_files, failed_files
    
    async def _generate_with_semaphore(self, semaphore, file_path, file_data):
        """Generate a component with a semaphore to limit concurrent requests."""
        async with semaphore:
            return await self.generate_component(file_path, file_data)
    
    @retry(stop=stop_after_attempt(3), wait=wait_exponential(multiplier=1, min=2, max=10))
    async def generate_component(self, file_path: str, file_data: Dict[str, Any]):
        """
        Generate a single React component and save it to the appropriate location.
        
        Args:
            file_path: The path where the component should be saved
            file_data: Data about the component to be generated
        """
        try:
            # Create the directory if it doesn't exist
            target_path = self.output_dir / file_path
            target_dir = target_path.parent
            target_dir.mkdir(parents=True, exist_ok=True)
            
            # Skip if the file already exists (to support resuming)
            if target_path.exists():
                logger.info(f"File already exists, skipping: {file_path}")
                return True
            
            # Get the dependencies
            dependencies = file_data.get("dependencies", [])
            dependency_contents = await self._get_dependency_contents(dependencies)
            
            # Generate different prompts based on file type
            file_type = file_data.get("file_type", "js")
            
            if file_type in ["js", "jsx"]:
                prompt = self._build_component_prompt(file_path, file_data, dependency_contents)
            elif file_type == "css":
                prompt = self._build_css_prompt(file_path, file_data, dependency_contents)
            elif file_type == "json":
                prompt = self._build_json_prompt(file_path, file_data, dependency_contents)
            else:
                prompt = self._build_generic_prompt(file_path, file_data, dependency_contents)
            
            # Get the generated code from the AI
            component_code = await self._query_llm(prompt)
            
            # Extract the code from the AI response
            clean_code = self._extract_code(component_code, file_type)
            
            # Save the file
            with open(target_path, 'w', encoding='utf-8') as f:
                f.write(clean_code)
                
            logger.info(f"Successfully generated: {file_path}")
            return True
            
        except Exception as e:
            logger.error(f"Error generating {file_path}: {str(e)}")
            raise
    
    async def _get_dependency_contents(self, dependencies: List[str]) -> Dict[str, str]:
        """
        Retrieve the content of the component's dependencies.
        
        Args:
            dependencies: List of dependency paths
            
        Returns:
            Dict mapping dependency paths to their contents
        """
        dependency_contents = {}
        
        for dep_path in dependencies:
            # Skip external dependencies
            if dep_path.startswith(('http://', 'https://', '//')):
                logger.info(f"Skipping external dependency: {dep_path}")
                continue
                
            # Normalize path for matching
            normalized_path = dep_path.replace('\\', '/')
            
            # Try direct lookup first
            if normalized_path in self.source_files:
                dependency_contents[dep_path] = self.source_files[normalized_path]
                continue
            
            # Try path variations
            variations = [
                normalized_path,
                normalized_path.replace('/', '\\'),
                os.path.basename(normalized_path),
                # Try without extension
                os.path.splitext(normalized_path)[0],
                # Try with common extensions
                f"{normalized_path}.js",
                f"{normalized_path}.html",
                f"{normalized_path}.css"
            ]
            
            found = False
            for variant in variations:
                if variant in self.source_files:
                    dependency_contents[dep_path] = self.source_files[variant]
                    logger.info(f"Found content for {dep_path} using variant: {variant}")
                    found = True
                    break
            
            if not found:
                # Try to find by similar name
                basename = os.path.basename(normalized_path)
                for src_path in self.source_files:
                    if basename.lower() in src_path.lower():
                        dependency_contents[dep_path] = self.source_files[src_path]
                        logger.info(f"Found similar match for {dep_path}: {src_path}")
                        found = True
                        break
            
            if not found:
                logger.warning(f"Could not find content for dependency: {dep_path}")
                dependency_contents[dep_path] = f"// Content not found for {dep_path}"
        
        return dependency_contents
    
    def _build_component_prompt(self, file_path: str, file_data: Dict[str, Any], dependency_contents: Dict[str, str]) -> str:
        """
        Build a detailed prompt for generating a React JS/JSX component.
        
        Args:
            file_path: Path of the component to generate
            file_data: Data about the component
            dependency_contents: Contents of the component's dependencies
            
        Returns:
            String containing the prompt for the AI
        """
        # Get component name from file path
        component_name = os.path.basename(file_path).split('.')[0]
        
        prompt = f"""
You are an expert in modern React development and Angular to React migration.

I need you to create a React component for: {file_path}

Component information:
- Name: {component_name}
- Purpose: {file_data.get('migration_suggestion', 'React component')}
- Routing: {file_data.get('routing_info', 'N/A')}

This React component should be based on these AngularJS source files:
"""
        
        # Add dependency contents
        for dep_path, content in dependency_contents.items():
            # Get short name for display
            short_name = os.path.basename(dep_path)
            
            prompt += f"""
### Source file: {short_name} ({dep_path})
```
{content}
```

"""
        
        # Add React-specific instructions
        prompt += """
## Requirements
Create a modern React component following these guidelines:
- Use functional components with hooks (NOT class components)
- Use ES6+ syntax
- Include proper prop types (using PropTypes)
- Implement proper state management with useState/useContext/useReducer as needed
- Handle any necessary side effects with useEffect
- Use async/await for asynchronous operations
- For forms, use controlled components
- Implement proper error handling
- If this component needs routing, use React Router v6 syntax
- Make sure all AngularJS functionality is properly converted to React equivalents

## Output Format
Return ONLY the complete React component code, properly formatted and ready to use.
Do not include markdown code blocks or explanations.
"""
        
        return prompt
    
    def _build_css_prompt(self, file_path: str, file_data: Dict[str, Any], dependency_contents: Dict[str, str]) -> str:
        """Build a prompt for generating CSS files."""
        prompt = f"""
You are an expert in modern CSS and web styling, with experience in migrating Angular projects to React.

I need you to create a CSS file for: {file_path}

File information:
- Purpose: {file_data.get('migration_suggestion', 'Styling for React components')}

This CSS should be based on these AngularJS source files:
"""
        
        # Add dependency contents
        for dep_path, content in dependency_contents.items():
            short_name = os.path.basename(dep_path)
            prompt += f"""
### Source file: {short_name} ({dep_path})
```
{content}
```

"""
        
        # Add CSS-specific instructions
        prompt += """
## Requirements
Create modern CSS following these guidelines:
- Use modular CSS approach (the file will be imported as a CSS module)
- Ensure class names follow the BEM methodology or a similar naming convention
- Include responsive design considerations
- Optimize for modern browsers while maintaining compatibility
- Convert any Angular-specific styling to React-compatible CSS
- Ensure all styles from the original Angular application are properly migrated

## Output Format
Return ONLY the complete CSS code, properly formatted and ready to use.
Do not include markdown code blocks or explanations.
"""
        
        return prompt
    
    def _build_json_prompt(self, file_path: str, file_data: Dict[str, Any], dependency_contents: Dict[str, str]) -> str:
        """Build a prompt for generating JSON files."""
        prompt = f"""
You are an expert in React project configuration and package management.

I need you to create a JSON configuration file for: {file_path}

File information:
- Purpose: {file_data.get('migration_suggestion', 'Configuration for React project')}

"""
        
        # For package.json, add special instructions
        if file_path.lower() == "package.json":
            prompt += """
## Requirements
Create a package.json for a modern React application that:
- Includes all necessary React dependencies (react, react-dom, react-router-dom, etc.)
- Includes development dependencies for a typical React project
- Defines useful scripts (start, build, test, etc.)
- Sets appropriate metadata (name, version, description, etc.)
- Configures necessary browser compatibility settings
- Includes any necessary configuration for tools like ESLint, Prettier, etc.

For React, include:
- React 18 or newer
- React Router 6 or newer
- PropTypes for type checking
- Any utility libraries needed (such as classnames, lodash, axios)
- Testing libraries (Jest, React Testing Library)
"""
        else:
            # Add dependency contents
            for dep_path, content in dependency_contents.items():
                short_name = os.path.basename(dep_path)
                prompt += f"""
### Source file: {short_name} ({dep_path})
```
{content}
```

"""
            
            prompt += """
## Requirements
Create a valid JSON file that:
- Follows proper JSON syntax
- Includes all necessary configuration
- Is properly formatted and readable
- Converts any Angular-specific configuration to React equivalents
"""
        
        prompt += """
## Output Format
Return ONLY the complete JSON code, properly formatted and ready to use.
Do not include markdown code blocks or explanations.
"""
        
        return prompt
    
    def _build_generic_prompt(self, file_path: str, file_data: Dict[str, Any], dependency_contents: Dict[str, str]) -> str:
        """Build a generic prompt for other file types."""
        file_type = file_data.get("file_type", "")
        
        prompt = f"""
You are an expert in modern web development and Angular to React migration.

I need you to create a {file_type} file for: {file_path}

File information:
- Type: {file_type}
- Purpose: {file_data.get('migration_suggestion', 'Support file for React project')}

This file should be based on these AngularJS source files:
"""
        
        # Add dependency contents
        for dep_path, content in dependency_contents.items():
            short_name = os.path.basename(dep_path)
            prompt += f"""
### Source file: {short_name} ({dep_path})
```
{content}
```

"""
        
        # Add generic instructions
        prompt += f"""
## Requirements
Create a {file_type} file that:
- Follows best practices for {file_type} files
- Is properly formatted and ready to use
- Converts any Angular-specific content to React equivalents
- Maintains the same functionality as the original file

## Output Format
Return ONLY the complete code, properly formatted and ready to use.
Do not include markdown code blocks or explanations.
"""
        
        return prompt
    
    async def _query_llm(self, prompt: str) -> str:
        """
        Query the language model with the given prompt.
        
        Args:
            prompt: The prompt to send to the language model
            
        Returns:
            String containing the response from the LLM
        """
        try:
            # Use langchain LLM for code generation
            return await self.llm_config._langchain_llm.apredict(prompt)
        except Exception as e:
            raise Exception(f"Error querying LLM: {str(e)}")
            
    def _extract_code(self, response: str, file_type: str) -> str:
        """
        Extract clean code from the AI response.
        
        Args:
            response: The raw response from the AI
            file_type: The type of file being generated
            
        Returns:
            String containing the clean code
        """
        # First, check if the entire response is valid code (no markdown)
        if not response.strip().startswith("```") and not response.strip().startswith("#"):
            # If it looks like clean code already, return it
            return response.strip()
        
        # Otherwise, look for code blocks with the specified language
        code_block_pattern = re.compile(rf"```(?:{file_type})?\s*([\s\S]*?)\s*```")
        matches = code_block_pattern.findall(response)
        
        if matches:
            # Return the largest code block (in case there are multiple)
            return max(matches, key=len).strip()
        
        # If no specific code blocks found, try generic code blocks
        generic_code_block = re.compile(r"```\s*([\s\S]*?)\s*```")
        generic_matches = generic_code_block.findall(response)
        
        if generic_matches:
            return max(generic_matches, key=len).strip()
        
        # Handle specific file types
        if file_type == "json":
            # For JSON, find content between { and }
            json_pattern = re.compile(r"(\{[\s\S]*\})")
            json_matches = json_pattern.findall(response)
            if json_matches:
                return max(json_matches, key=len).strip()
                
        # For other file types or if nothing specific was found, 
        # clean the response to remove markdown artifacts
        
        # Remove code block markers
        cleaned = re.sub(r"```.*?```", "", response, flags=re.DOTALL)
        # Remove markdown headers
        cleaned = re.sub(r"^#.*$", "", cleaned, flags=re.MULTILINE)
        # Remove bold/italic formatting
        cleaned = re.sub(r"\*\*|\*|__|\^", "", cleaned)
        # Remove horizontal rules
        cleaned = re.sub(r"^\-\-\-+$", "", cleaned, flags=re.MULTILINE)
        
        return cleaned.strip()