import json
import os
from pathlib import Path
import asyncio
from typing import Dict, List, Any, Optional, Union
import logging
import re
from tenacity import retry, stop_after_attempt, wait_exponential

# Set up logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class ReactComponentGenerator:
    """
    Generates React component files from AngularJS source files using AI assistance.
    
    This class takes the migration structure generated by ReactMigrationStructureGenerator
    and creates actual React component files, placing them in the correct directory structure.
    """
    
    def __init__(self, migration_file: str, analysis_file: str, output_dir: Union[str, Path], llm_config: Any):
        """
        Initialize the ReactComponentGenerator.
        
        Args:
            migration_file: Path to the JSON file containing the React migration structure
            analysis_file: Path to the JSON file containing the AngularJS project analysis
            output_dir: Directory where the React files will be created
            llm_config: Configuration for the language model
        """
        self.migration_file = migration_file
        self.analysis_file = analysis_file
        self.output_dir = Path(output_dir)
        self.llm_config = llm_config
        self.migration_data = {}
        self.analysis_data = {}
        self.source_files = {}
        
    async def load_data(self):
        """Load the migration structure and analysis data."""
        try:
            with open(self.migration_file, 'r', encoding='utf-8') as f:
                self.migration_data = json.load(f)
                
            with open(self.analysis_file, 'r', encoding='utf-8') as f:
                self.analysis_data = json.load(f)
                
            logger.info(f"Successfully loaded migration and analysis data")
            
            # Remove metadata entries if present
            if "__metadata__" in self.migration_data:
                del self.migration_data["__metadata__"]
                
            # Remove project_structure entry if present (appears to be a duplicate)
            if "project_structure" in self.migration_data:
                del self.migration_data["project_structure"]
                
            # Process the analysis data to extract source files
            self._extract_source_files()
            
        except Exception as e:
            logger.error(f"Error loading data: {str(e)}")
            raise
    
    def _extract_source_files(self):
        """Extract source files from the analysis data."""
        if not isinstance(self.analysis_data, dict):
            logger.error("Analysis data is not a dictionary")
            return
            
        for file_path, file_info in self.analysis_data.items():
            if not isinstance(file_info, dict):
                continue
                
            # Get the content from the analysis data
            content = file_info.get('content', '')
            if not content and 'file_path' in file_info:
                # Try reading from actual file if content not in analysis
                try:
                    with open(file_info['file_path'], 'r', encoding='utf-8') as f:
                        content = f.read()
                except Exception as e:
                    logger.warning(f"Could not read file {file_info['file_path']}: {str(e)}")
                    continue
            
            if content:
                # Store both relative and absolute paths for flexibility
                relative_path = file_info.get('relative_path', file_path)
                self.source_files[file_path] = content
                self.source_files[relative_path] = content
                
                # Also store without extension for more flexible matching
                base_path = os.path.splitext(file_path)[0]
                if base_path != file_path:
                    self.source_files[base_path] = content
                    
        logger.info(f"Extracted {len(self.source_files)} source files from analysis data")
    
    async def generate_all_components(self):
        """Generate all React components based on the migration structure."""
        try:
            await self.load_data()
            
            # Create output directory if it doesn't exist
            self.output_dir.mkdir(parents=True, exist_ok=True)
            
            # Generate each component
            for file_path, file_info in self.migration_data.items():
                try:
                    logger.info(f"Generating: {file_path}")
                    
                    # Get dependencies content first
                    dependencies = file_info.get("dependencies", [])
                    dependency_contents = await self._get_dependency_contents(dependencies)
                    
                    # Build the prompt
                    prompt = self._build_component_prompt(file_path, file_info, dependency_contents)
                    
                    # Generate the component code
                    response = await self.llm_config._langchain_llm.apredict(prompt)
                    
                    # Extract code from response
                    component_code = self._extract_code(response, file_info["file_type"])
                    
                    # Create the output path
                    output_path = self.output_dir / file_info["relative_path"]
                    output_path.parent.mkdir(parents=True, exist_ok=True)
                    
                    # Write the component to file
                    with open(output_path, "w", encoding="utf-8") as f:
                        f.write(component_code)
                        
                    logger.info(f"Successfully generated: {file_path}")
                    
                except Exception as e:
                    logger.error(f"Error generating {file_path}: {str(e)}")
                    continue
                    
        except Exception as e:
            logger.error(f"Error generating components: {str(e)}")
            raise
            
    def _build_component_prompt(self, file_path: str, file_info: Dict[str, Any], dependency_contents: Dict[str, str]) -> str:
        """
        Build a prompt for generating a React component.
        
        Args:
            file_path: Path of the component to generate
            file_info: Dictionary containing file information
            dependency_contents: Contents of dependencies
            
        Returns:
            Prompt string for the LLM
        """
        try:
            # Get the source files content
            source_files_content = []
            for source_file in file_info.get("source_files", []):
                if source_file in self.source_files:
                    source_files_content.append({
                        "name": source_file,
                        "content": self.source_files[source_file],
                        "type": "js" if source_file.endswith(".js") else "html" if source_file.endswith(".html") else "unknown"
                    })
            
            # Build the prompt based on file type
            file_type = file_info.get("file_type", "js")
            
            if file_type == "json":
                base_prompt = """Generate a {file_type} file that:
1. Follows standard {file_type} format
2. Includes all necessary dependencies
3. Matches the migration requirements
4. Is properly formatted and valid

Original source files are provided for reference.
"""
            elif file_type == "css":
                base_prompt = """Generate a {file_type} file that:
1. Implements all necessary styles
2. Uses modern CSS practices
3. Maintains equivalent styling to AngularJS
4. Is clean and well-organized

Original source files are provided for reference.
"""
            else:
                base_prompt = """Generate a React component that:
1. Includes all necessary imports
2. Uses modern React practices (functional components, hooks)
3. Implements equivalent functionality to the AngularJS code
4. Follows the migration suggestions
5. Handles routing appropriately
6. Uses the specified dependencies

Original source files are provided for reference.
"""
            
            # Build the main prompt
            prompt = f"""Generate a React {file_info['file_type']} component for {file_info['relative_path']}.

Component Information:
- Description: {file_info['description']}
- Dependencies: {', '.join(file_info['dependencies'])}
- Migration Notes: {file_info['migration_suggestions']}
- Routing Info: {file_info['routing_info']}

Original AngularJS Source Files:
"""

            # Add source files
            for source in source_files_content:
                prompt += f"\n{source['name']} ({source['type']}):\n```\n{source['content']}\n```\n"
            
            # Add dependency contents if any
            if dependency_contents:
                prompt += "\nDependency Files:\n"
                for dep_path, dep_content in dependency_contents.items():
                    prompt += f"\n{dep_path}:\n```\n{dep_content}\n```\n"
            
            # Add the base prompt
            prompt += "\n" + base_prompt.format(file_type=file_info['file_type'])
            
            # Add final instruction
            prompt += "\nReturn ONLY the code wrapped in a code block."
            
            return prompt
            
        except Exception as e:
            logger.error(f"Error building prompt: {str(e)}")
            raise
    
    async def _get_dependency_contents(self, dependencies: List[str]) -> Dict[str, str]:
        """
        Retrieve the content of the component's dependencies.
        
        Args:
            dependencies: List of dependency paths
            
        Returns:
            Dict mapping dependency paths to their contents
        """
        dependency_contents = {}
        
        for dep_path in dependencies:
            # Skip external dependencies
            if dep_path.startswith(('http://', 'https://', '//')):
                logger.info(f"Skipping external dependency: {dep_path}")
                continue
                
            # Normalize path for matching
            normalized_path = dep_path.replace('\\', '/')
            
            # Try direct lookup first
            if normalized_path in self.source_files:
                dependency_contents[dep_path] = self.source_files[normalized_path]
                continue
            
            # Try path variations
            variations = [
                normalized_path,
                normalized_path.replace('/', '\\'),
                os.path.basename(normalized_path),
                # Try without extension
                os.path.splitext(normalized_path)[0],
                # Try with common extensions
                f"{normalized_path}.js",
                f"{normalized_path}.html",
                f"{normalized_path}.css"
            ]
            
            found = False
            for variant in variations:
                if variant in self.source_files:
                    dependency_contents[dep_path] = self.source_files[variant]
                    logger.info(f"Found content for {dep_path} using variant: {variant}")
                    found = True
                    break
            
            if not found:
                # Try to find by similar name
                basename = os.path.basename(normalized_path)
                for src_path in self.source_files:
                    if basename.lower() in src_path.lower():
                        dependency_contents[dep_path] = self.source_files[src_path]
                        logger.info(f"Found similar match for {dep_path}: {src_path}")
                        found = True
                        break
            
            if not found:
                logger.warning(f"Could not find content for dependency: {dep_path}")
                dependency_contents[dep_path] = f"// Content not found for {dep_path}"
        
        return dependency_contents
    
    @retry(stop=stop_after_attempt(3), wait=wait_exponential(multiplier=1, min=2, max=10))
    async def generate_component(self, file_path: str, file_data: Dict[str, Any]):
        """
        Generate a single React component and save it to the appropriate location.
        
        Args:
            file_path: The path where the component should be saved
            file_data: Data about the component to be generated
        """
        try:
            # Create the directory if it doesn't exist
            target_path = self.output_dir / file_path
            target_dir = target_path.parent
            target_dir.mkdir(parents=True, exist_ok=True)
            
            # Skip if the file already exists (to support resuming)
            if target_path.exists():
                logger.info(f"File already exists, skipping: {file_path}")
                return True
            
            # Get the dependencies
            dependencies = file_data.get("dependencies", [])
            dependency_contents = await self._get_dependency_contents(dependencies)
            
            # Generate different prompts based on file type
            file_type = file_data.get("file_type", "js")
            
            if file_type in ["js", "jsx"]:
                prompt = self._build_component_prompt(file_path, file_data, dependency_contents)
            elif file_type == "css":
                prompt = self._build_css_prompt(file_path, file_data, dependency_contents)
            elif file_type == "json":
                prompt = self._build_json_prompt(file_path, file_data, dependency_contents)
            else:
                prompt = self._build_generic_prompt(file_path, file_data, dependency_contents)
            
            # Get the generated code from the AI
            component_code = await self._query_llm(prompt)
            
            # Extract the code from the AI response
            clean_code = self._extract_code(component_code, file_type)
            
            # Save the file
            with open(target_path, 'w', encoding='utf-8') as f:
                f.write(clean_code)
                
            logger.info(f"Successfully generated: {file_path}")
            return True
            
        except Exception as e:
            logger.error(f"Error generating {file_path}: {str(e)}")
            raise
    
    async def _query_llm(self, prompt: str) -> str:
        """
        Query the language model with the given prompt.
        
        Args:
            prompt: The prompt to send to the language model
            
        Returns:
            String containing the response from the LLM
        """
        try:
            # Use langchain LLM for code generation
            return await self.llm_config._langchain_llm.apredict(prompt)
        except Exception as e:
            raise Exception(f"Error querying LLM: {str(e)}")
            
    def _extract_code(self, response: str, file_type: str) -> str:
        """
        Extract clean code from the AI response.
        
        Args:
            response: The raw response from the AI
            file_type: The type of file being generated
            
        Returns:
            String containing the clean code
        """
        # First, check if the entire response is valid code (no markdown)
        if not response.strip().startswith("```") and not response.strip().startswith("#"):
            # If it looks like clean code already, return it
            return response.strip()
        
        # Otherwise, look for code blocks with the specified language
        code_block_pattern = re.compile(rf"```(?:{file_type})?\s*([\s\S]*?)\s*```")
        matches = code_block_pattern.findall(response)
        
        if matches:
            # Return the largest code block (in case there are multiple)
            return max(matches, key=len).strip()
        
        # If no specific code blocks found, try generic code blocks
        generic_code_block = re.compile(r"```\s*([\s\S]*?)\s*```")
        generic_matches = generic_code_block.findall(response)
        
        if generic_matches:
            return max(generic_matches, key=len).strip()
        
        # Handle specific file types
        if file_type == "json":
            # For JSON, find content between { and }
            json_pattern = re.compile(r"(\{[\s\S]*\})")
            json_matches = json_pattern.findall(response)
            if json_matches:
                return max(json_matches, key=len).strip()
                
        # For other file types or if nothing specific was found, 
        # clean the response to remove markdown artifacts
        
        # Remove code block markers
        cleaned = re.sub(r"```.*?```", "", response, flags=re.DOTALL)
        # Remove markdown headers
        cleaned = re.sub(r"^#.*$", "", cleaned, flags=re.MULTILINE)
        # Remove bold/italic formatting
        cleaned = re.sub(r"\*\*|\*|__|\^", "", cleaned)
        # Remove horizontal rules
        cleaned = re.sub(r"^\-\-\-+$", "", cleaned, flags=re.MULTILINE)
        
        return cleaned.strip()
    
    def _build_css_prompt(self, file_path: str, file_data: Dict[str, Any], dependency_contents: Dict[str, str]) -> str:
        """Build a prompt for generating CSS files."""
        prompt = f"""
You are an expert in modern CSS and web styling, with experience in migrating Angular projects to React.

I need you to create a CSS file for: {file_path}

File information:
- Purpose: {file_data.get('migration_suggestion', 'Styling for React components')}

This CSS should be based on these AngularJS source files:
"""
        
        # Add dependency contents
        for dep_path, content in dependency_contents.items():
            short_name = os.path.basename(dep_path)
            prompt += f"""
### Source file: {short_name} ({dep_path})
```
{content}
```

"""
        
        # Add CSS-specific instructions
        prompt += """
## Requirements
Create modern CSS following these guidelines:
- Use modular CSS approach (the file will be imported as a CSS module)
- Ensure class names follow the BEM methodology or a similar naming convention
- Include responsive design considerations
- Optimize for modern browsers while maintaining compatibility
- Convert any Angular-specific styling to React-compatible CSS
- Ensure all styles from the original Angular application are properly migrated

## Output Format
Return ONLY the complete CSS code, properly formatted and ready to use.
Do not include markdown code blocks or explanations.
"""
        
        return prompt
    
    def _build_json_prompt(self, file_path: str, file_data: Dict[str, Any], dependency_contents: Dict[str, str]) -> str:
        """Build a prompt for generating JSON files."""
        prompt = f"""
You are an expert in React project configuration and package management.

I need you to create a JSON configuration file for: {file_path}

File information:
- Purpose: {file_data.get('migration_suggestion', 'Configuration for React project')}

"""
        
        # For package.json, add special instructions
        if file_path.lower() == "package.json":
            prompt += """
## Requirements
Create a package.json for a modern React application that:
- Includes all necessary React dependencies (react, react-dom, react-router-dom, etc.)
- Includes development dependencies for a typical React project
- Defines useful scripts (start, build, test, etc.)
- Sets appropriate metadata (name, version, description, etc.)
- Configures necessary browser compatibility settings
- Includes any necessary configuration for tools like ESLint, Prettier, etc.

For React, include:
- React 18 or newer
- React Router 6 or newer
- PropTypes for type checking
- Any utility libraries needed (such as classnames, lodash, axios)
- Testing libraries (Jest, React Testing Library)
"""
        else:
            # Add dependency contents
            for dep_path, content in dependency_contents.items():
                short_name = os.path.basename(dep_path)
                prompt += f"""
### Source file: {short_name} ({dep_path})
```
{content}
```

"""
            
            prompt += """
## Requirements
Create a valid JSON file that:
- Follows proper JSON syntax
- Includes all necessary configuration
- Is properly formatted and readable
- Converts any Angular-specific configuration to React equivalents
"""
        
        prompt += """
## Output Format
Return ONLY the complete JSON code, properly formatted and ready to use.
Do not include markdown code blocks or explanations.
"""
        
        return prompt
    
    def _build_generic_prompt(self, file_path: str, file_data: Dict[str, Any], dependency_contents: Dict[str, str]) -> str:
        """Build a generic prompt for other file types."""
        file_type = file_data.get("file_type", "")
        
        prompt = f"""
You are an expert in modern web development and Angular to React migration.

I need you to create a {file_type} file for: {file_path}

File information:
- Type: {file_type}
- Purpose: {file_data.get('migration_suggestion', 'Support file for React project')}

This file should be based on these AngularJS source files:
"""
        
        # Add dependency contents
        for dep_path, content in dependency_contents.items():
            short_name = os.path.basename(dep_path)
            prompt += f"""
### Source file: {short_name} ({dep_path})
```
{content}
```

"""
        
        # Add generic instructions
        prompt += f"""
## Requirements
Create a {file_type} file that:
- Follows best practices for {file_type} files
- Is properly formatted and ready to use
- Converts any Angular-specific content to React equivalents
- Maintains the same functionality as the original file

## Output Format
Return ONLY the complete code, properly formatted and ready to use.
Do not include markdown code blocks or explanations.
"""
        
        return prompt